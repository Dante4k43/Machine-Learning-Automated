{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IybLoj3qdMYd"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit pyngrok shap xgboost transformers scikit-learn pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "import requests\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Set Hugging Face API token\n",
        "os.environ[\"HF_TOKEN\"] = \"REPLACE WITH YOURS\"\n",
        "\n",
        "def ask_llm(prompt):\n",
        "    api_url = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
        "    headers = {\"Authorization\": f\"Bearer {os.environ['HF_TOKEN']}\"}\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": 300,\n",
        "            \"temperature\": 0.7\n",
        "        }\n",
        "    }\n",
        "    response = requests.post(api_url, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[0]['generated_text']\n",
        "    else:\n",
        "        return f\"Error: {response.status_code} - {response.text}\"\n",
        "\n",
        "st.title(\"Colab Streamlit: Train Model and Explain Predictions\")\n",
        "\n",
        "# File upload\n",
        "uploaded = st.file_uploader(\"Upload a CSV dataset\", type=\"csv\")\n",
        "if uploaded is not None:\n",
        "    df = pd.read_csv(uploaded)\n",
        "    st.write(\"Dataset preview:\", df.head())\n",
        "\n",
        "    target = st.selectbox(\"Select target column\", df.columns)\n",
        "    target_type = st.radio(\"Is the target categorical or numerical?\", (\"Numerical\", \"Categorical\"))\n",
        "\n",
        "    # Encode non-numeric columns\n",
        "    df_clean = df.copy()\n",
        "    for col in df_clean.columns:\n",
        "        if col != target and df_clean[col].dtype == object:\n",
        "            df_clean[col] = LabelEncoder().fit_transform(df_clean[col].astype(str))\n",
        "    df_clean = df_clean.dropna()\n",
        "    X = df_clean.drop(columns=[target])\n",
        "    y = df_clean[target]\n",
        "\n",
        "    if target_type == \"Categorical\":\n",
        "        le_target = LabelEncoder()\n",
        "        y = le_target.fit_transform(y.astype(str))\n",
        "\n",
        "    # Choose model\n",
        "    if target_type == \"Numerical\":\n",
        "        model_name = st.selectbox(\"Choose model\", (\"Decision Tree Regressor\", \"Linear Regression\", \"XGBoost Regressor\"))\n",
        "    else:\n",
        "        model_name = st.selectbox(\"Choose model\", (\"Decision Tree Classifier\", \"XGBoost Classifier\"))\n",
        "\n",
        "    # Train model\n",
        "    if st.button(\"Train Model\"):\n",
        "        if target_type == \"Numerical\":\n",
        "            if model_name == \"Decision Tree Regressor\":\n",
        "                model = DecisionTreeRegressor(max_depth=5)\n",
        "            elif model_name == \"Linear Regression\":\n",
        "                model = LinearRegression()\n",
        "            else:\n",
        "                model = XGBRegressor(objective='reg:squarederror', n_estimators=100, verbosity=0)\n",
        "        else:\n",
        "            if model_name == \"Decision Tree Classifier\":\n",
        "                model = DecisionTreeClassifier(max_depth=5)\n",
        "            else:\n",
        "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, verbosity=0)\n",
        "\n",
        "        model.fit(X, y)\n",
        "        st.success(f\"Trained {model_name} on the data.\")\n",
        "        time.sleep(2)\n",
        "\n",
        "        preds = model.predict(X)\n",
        "        if target_type == \"Numerical\":\n",
        "            mse = mean_squared_error(y, preds)\n",
        "            st.write(f\"Mean Squared Error on training set: {mse:.3f}\")\n",
        "        else:\n",
        "            acc = accuracy_score(y, preds)\n",
        "            st.write(f\"Accuracy on training set: {acc:.2f}\")\n",
        "\n",
        "        # Feature importance (only for tree-based models)\n",
        "        st.subheader(\"Top Features Based on Model Importance\")\n",
        "        try:\n",
        "            importances = model.feature_importances_\n",
        "            feat_df = pd.DataFrame({\n",
        "                'Feature': X.columns,\n",
        "                'Importance': importances\n",
        "            }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "            st.dataframe(feat_df.head(5), use_container_width=True)\n",
        "\n",
        "            # Generate prompt for LLM\n",
        "            explanation_prompt = \"Explain what the following top features might mean in terms of their influence on a machine learning model's prediction target. Use simple language:\\n\\n\"\n",
        "            for _, row in feat_df.head(5).iterrows():\n",
        "                explanation_prompt += f\"- {row['Feature']} (Importance: {row['Importance']:.4f})\\n\"\n",
        "            explanation_prompt += \"\\nBe clear and intuitive.\"\n",
        "\n",
        "            with st.spinner(\"Generating interpretation using Mistral...\"):\n",
        "                result = ask_llm(explanation_prompt)\n",
        "\n",
        "            st.subheader(\"AI-Generated Interpretation\")\n",
        "            st.markdown(result)\n",
        "\n",
        "        except AttributeError:\n",
        "            st.warning(\"This model does not provide feature importances. Try a tree-based model like XGBoost or Decision Tree.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rDJxlPgIGbx",
        "outputId": "ab51b430-a1f9-437c-926b-f35087f9995d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "import os, time\n",
        "\n",
        "# Configure Ngrok\n",
        "conf.get_default().auth_token = \"REPLACE WITH YOURS\"\n",
        "\n",
        "# Kill previous sessions\n",
        "os.system(\"pkill streamlit\")\n",
        "\n",
        "# Launch Streamlit\n",
        "os.system(\"nohup streamlit run app.py --server.port 8501 > log.txt 2>&1 &\")\n",
        "\n",
        "\n",
        "# Open ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit app is live at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il24rH55dNq8",
        "outputId": "83038c46-a915-4961-fd05-260ae189ee5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://5eb6-35-193-23-63.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K51hSovegqZn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}